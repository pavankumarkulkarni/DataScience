---
title: "SVM"
output: 
  html_document: 
    highlight: pygments
    number_sections: yes
    theme: journal
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scrolling: yes
---

# Thoery:  
## Maximal Margin Classifier :  
  Let us consider the scenario where 2 class observations can be cleanly seperated. These classes can then be seperated by p-dimension hyperplane. (p-dimension observations). However there can be infinitely large number of hyperplanes which can divide these 2 classes of  observations. Infinitely large number of Hyper planes can be generated by simply varying one of the p-coeffecients of the plane or intercept.  
  **Maximal Margin Classifier** : Below steps can be followed to idenrify maximal margin classifier.  
  1. Calculate the perpendicular distance of one of hyperplance with each of the observations.  
  2. Identify the minimum distance of the plane from both classes of observations.  
  3. Select the p-dimensional hyperplane which has the maximum of minimum distance identified in step 2. This is  the 'maximum margin classifier'.  
  
  Set of observations which have minimum distance with maximum margin classifier are 'supporting' the hyperplane and are vectors. Hence they are called **support vectors**. Other observations which are far from this seperating hyperplance don't effect the classifier.  
  
## Support Vector Classifiers:  
  Most of the real life scenarios, observations can't be cleanly seperated into classes. In these cases maximum margin classifier is generalised and is called **Support Vector Classifier**. Here hyper plane is developed which 'almost' devides classes of observations using soft margin. Support vector classifier can have few observations on wrong side of the margin and even on wrong side of the plane. This is inevitable in case where observations can't be cleanly seperated. Also to make the model more robust to test observations it is necessary else the classifier will become too sensitive to training observations.  
  
  There is a tuning parameter usually denoted by 'c'. This tuning parameter can be thought of as the budget of violation which n-observations can violate margin and severity of violations. 0 tuning parameter is maximum margin classifier. Larger the 'c' more violations are tolerated. Usually best cost factor (tuning facotr) c is selected by cross validations.  
  
   An interesting property of the classifier is all observation which are on right side of the plane and margin don't effect the hyper plane. Only observations on the margin, wrong side of the margin and wrong side of the class support the **Support Vector classifier**.  
   
## Support Vector machines:  

It is extension of support vector classifier where feature space is  expanded in certain way by using *kernels*. These kernels can be linear,non linear or even radials.  

# Application of SVM.  

R package 'e1071' has method svm to calculate support vector machines.  

## UCI Glass identification:  

Dataset is taken from UCI Classification library [here](http://archive.ics.uci.edu/ml/machine-learning-databases/glass/)  

Attribute Information:  
   1. Id number: 1 to 214  
   2. RI: refractive index  
   3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)  
   4. Mg: Magnesium  
   5. Al: Aluminum  
   6. Si: Silicon  
   7. K: Potassium  
   8. Ca: Calcium  
   9. Ba: Barium  
  10. Fe: Iron  
  11. Type of glass: (class attribute)  
      -- 1 building_windows_float_processed  
      -- 2 building_windows_non_float_processed  
      -- 3 vehicle_windows_float_processed  
      -- 4 vehicle_windows_non_float_processed (none in this database)  
      -- 5 containers  
      -- 6 tableware  
      -- 7 headlamps  

The objective is to use SVM to classify type_glass based on chemical composition.  

### Load data
```{r Glass_Load_data, cache=TRUE,warning=FALSE}
df_gl <- read.csv('.//Data//UCI_GLASS.csv',header=FALSE)
colnames(df_gl) <- c('Id','RI','Na','Mg','Al','Si','K','Ca','Ba','Fe','Type_glass')
df_gl$Type_glass <- as.factor(df_gl$Type_glass) # code type as factor.
summary(df_gl)
sum(is.na(df_gl)) # No missing Values
```
### EDA
```{r Glass_EDA, cache = TRUE, warning=FALSE,fig.width=16,fig.height=12}
library(GGally)
ggpairs(df_gl[,-c(1)], upper=list(combo="box_no_facet"))
```  
  
### Run SVM

```{r Glass_SVM,cache=TRUE, warning=FALSE}
# split the data into train and test @ 80% 20% ratio.
library(e1071)
set.seed(1023)
training <- sample(seq(1:nrow(df_gl)),nrow(df_gl)*0.8)
train_gl <- df_gl[training,-c(1)] # id column is not needed
test_gl <- df_gl[-training,-c(1)] 
mod_fit <- svm(Type_glass~.,train_gl,cost=100,gamma=1)
mod_pre <- predict(mod_fit,train_gl)
# training error rate
table(mod_pre,train_gl$Type_glass) # 100% accuracy !!! 
test_mod_pre <- predict(mod_fit,test_gl[,-c(11)])
# test error rate
table(test_mod_pre,test_gl$Type_glass) # 100% accuracy !!! 
conf_t <- table(test_mod_pre,test_gl$Type_glass)
conf_t
classAgreement(conf_t)
plot(mod_fit,test_gl,RI~Mg)
```
  
Error rate on test data is `r (7+1+1)/sum(conf_t)*100`%.  

### Tune the model  

```{r glass_tune, cache=TRUE, warning=FALSE}
tune_mod <- tune(svm,Type_glass~.,data=train_gl, ranges=list(cost=c(0.1,1,10,100,200,500,1000),kernel=c('linear','radial')),gamma=1)
summary(tune_mod)
```


## UCI Breast Cancer Wisconsin (Diagnostic):  
Dataset is from UCI link [here](http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/).  

Attribute Information: (class attribute has been moved to last column)  

   #  Attribute                     Domain  
   -- -----------------------------------------  
   1. Sample code number            id number  
   2. Clump Thickness               1 - 10  
   3. Uniformity of Cell Size       1 - 10  
   4. Uniformity of Cell Shape      1 - 10  
   5. Marginal Adhesion             1 - 10  
   6. Single Epithelial Cell Size   1 - 10  
   7. Bare Nuclei                   1 - 10  
   8. Bland Chromatin               1 - 10  
   9. Normal Nucleoli               1 - 10  
  10. Mitoses                       1 - 10  
  11. Class:                        (2 for benign, 4 for malignant)  

### Load data  
```{r cancer_load, cache=TRUE, warning=TRUE}
cancer_raw <- read.csv('./Data/UCI_CANCER.csv',header=FALSE)
str(cancer_raw)
cancer_raw$V7 <- as.numeric(cancer_raw$V7) # by default read as factor which is not correct
cancer_raw$V11 <- as.factor(cancer_raw$V11) # this needs to be factor.
sum(is.na(cancer_raw)) # No missing value
summary(cancer_raw)
```

### EDA and data prep:  
```{r cancer_EDA, cache=TRUE,warning=FALSE, fig.width=14,fig.height=12}
library(GGally)
ggpairs(cancer_raw[,-c(1)],upper = list(combo = "box_no_facet"))
training <- sample(seq(1:nrow(cancer_raw)),nrow(cancer_raw)*0.8)
train_ccr <- cancer_raw[training,-c(1)]
test_ccr <- cancer_raw[-training,-c(1)]
nrow(train_ccr)
nrow(test_ccr)
```

### Find the best model  
```{r cancer_cv,cache=TRUE, warning=FALSE}
library(e1071)
best_mod <- tune.svm(V11~.,data=train_ccr,cost=10^(-1:1),gamma=10^(-6:1))
summary(best_mod)

```
### Evaluate best model on test data  
```{r cancer_eval, cache=TRUE, warning=FALSE}
model_fit <- svm(V11~.,data=train_ccr,cost=10, kernel='radial',gamma = 0.01)
model_pred <- predict(model_fit,test_ccr[,-c(10)])
tab <- table(model_pred,test_ccr$V11)
tab
classAgreement(tab)
```  

Prediction error rate on test data is `r (2+1)/sum(tab)*100`%.  

## SVM on Caravan dataset  

### Load dataset.  

* kNN classification was run on this dataset [here](KNN_Class.html).  
* Logistic Regression was run on this dataset [here](Log_Reg.html).  

```{r crvn_svm_load, cache=TRUE, warning=TRUE}
require(ISLR)
require(caret)
require(e1071)
attach(Caravan)
```  
  
### Split datasets.  
* 80% training data split using caret package.  

```{r crvn_svm_traintest, cache=TRUE, warning=TRUE}
trainIndex <- createDataPartition(Caravan$Purchase, p=0.8, list = F)
colRem <- nearZeroVar(Caravan,freqCut = 95/5)
CarColRem <- Caravan[,-colRem]
carTrain <- CarColRem[trainIndex,]
carTest <- CarColRem[-trainIndex,]
table(carTrain$Purchase)
```

### Balance Class.  
* `r 279/4380*100` is the 'Yes' class ratio. Need to balance class.  

```{r carv_balClass, cache=T, warning=T}
carTrainBal <- downSample(carTrain[,-51],carTrain$Purchase, yname='Purchase')
table(carTrainBal$Purchase)
```  
  
### SVM(linear) using caret interface.  
* By default linear SVM has only cost =1 value. Hence expanding the range of values.  
* Again we are interested in True Negative 'Specificity' metric.  
* Overwriting default metrics (accuracy, kappa and ROC) with *summaryFunction*.  
* 

```{r carvSVM, cache=T, warning=T}
set.seed(04092018)
tGrid <- expand.grid(C=c(0.05,0.1,0.25,0.5,0.75,1,1.5,1.75,2))
tuneControl <- trainControl(method='repeatedcv', number = 10, repeats = 3,
                            summaryFunction = twoClassSummary,
                            classProbs = TRUE)
crvn_svm_mod <- train(Purchase~.,data=carTrainBal,
                      method = 'svmLinear',
                      preProcess = c('center','scale'),
                      trControl = tuneControl,
                      tuneLength = 10,
                      tuneGrid = tGrid,
                      metric = 'Spec'
                      )
crvn_svm_mod
plot(crvn_svm_mod,metric = 'Spec')
svm_prd1 <- predict(crvn_svm_mod,carTest[,-51])
cfn <- confusionMatrix(svm_prd1,carTest$Purchase)
cfn
```  
  
* Test data set specificity is `r cfn$byClass['Specificity']*100`%.  

  
  
### SVM(non-linear) using caret interface.  
* By default linear SVM has only cost =1 value. Hence expanding the range of values.  
* Again we are interested in True Negative 'Specificity' metric.  
* Overwriting default metrics (accuracy, kappa and ROC) with *summaryFunction*.  
* 

```{r carvSVM_rad, cache=T, warning=T}
set.seed(04092018)
tGrid <- expand.grid(C=c(0.05,0.1,0.5,1,1.5,2),
                     sigma = c(0.05,0.1))
tuneControl <- trainControl(method='repeatedcv', number = 10, repeats = 3,
                            summaryFunction = twoClassSummary,
                            classProbs = TRUE)
crvn_svm_mod2 <- train(Purchase~.,data=carTrainBal,
                      method = 'svmRadial',
                      preProcess = c('center','scale'),
                      trControl = tuneControl,
                      tuneLength = 10,
                      tuneGrid = tGrid,
                      metric = 'Spec')
crvn_svm_mod2
plot(crvn_svm_mod2,metric = 'Spec')
svm_prd2 <- predict(crvn_svm_mod2,carTest[,-51])
cfn <- confusionMatrix(svm_prd2,carTest$Purchase)
cfn
```  
  
* Test data set specificity is `r cfn$byClass['Specificity']*100`%.